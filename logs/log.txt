[2018-09-02 16:47:16.640778]
Loading the data

[2018-09-02 16:47:17.412400]
Building input and output languages

[2018-09-02 16:48:10.099467]
Number of unique input tokens: 5957
Number of unique output tokens: 5138

[2018-09-02 16:48:10.107583]
Serializing input and output languages to pickles

[2018-09-02 16:48:10.138652]
Splitting data into train, validation, and test sets

[2018-09-02 16:48:10.461669]
Train size: 54417
Validation size: 7773
Test size: 15547

[2018-09-02 16:48:10.462047]
Serializing train, validation, and test sets to pickles

[2018-09-02 16:48:11.443448]
Converting data entries to tensors

[2018-09-02 16:48:19.485148]
Building the model

[2018-09-02 16:48:19.580253]
Seq2Seq(
  (encoder): EncoderRNN(
    (embedding): Embedding(5957, 256)
    (gru): GRU(256, 256)
  )
  (decoder): AttnDecoderRNN(
    (embedding): Embedding(5138, 256)
    (attn): Linear(in_features=512, out_features=51, bias=True)
    (attn_combine): Linear(in_features=512, out_features=256, bias=True)
    (dropout): Dropout(p=0.1)
    (gru): GRU(256, 256)
    (out): Linear(in_features=256, out_features=5138, bias=True)
  )
  (criterion): NLLLoss()
)

[2018-09-02 16:48:19.580624]
Initializing evaluators

[2018-09-02 16:48:19.581644]
Training the model

